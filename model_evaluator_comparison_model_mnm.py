# This file is used to evaluate the MnM model 2020.
import os
import sys
import cv2
import numpy as np
from benchmark import benchmark
from database import COLMAPDatabase
from feature_matching_generator_ML_comparison_models import feature_matcher_wrapper_generic_comparison_model_mnm
from query_image import load_images_from_text_file, get_localised_image_by_names, get_intrinsics_from_camera_bin
from ransac_prosac import ransac

# Read the original file model_evaluator.py for notes.
# Read also the original file create_training_data_and_train_for_match_no_match.py for notes.
# Similarly to model_evaluator.py, run in sequence NOT parallel
# In this file I get the matches then benchmark, and repeat not like in model_evaluator.py where I get all matches then benchmark

base_path = sys.argv[1]
base_path_mnm = sys.argv[2]
print("Base path: " + base_path)
print("Base (MnM, OpenCV) path: " + base_path_mnm)
no_samples = sys.argv[3] #the model was trained on

# The directory should be already created from previous scripts, create_training_data_predicting_matchability.py, create_training_data_and_train_for_match_no_match.py
comparison_data_path = os.path.join(base_path, "match_or_no_match_comparison_data")

if((os.path.exists(comparison_data_path) == False)):
    raise Exception("One of the dirs is not created!")

print("Loading Data..")
query_images_path = os.path.join(base_path, "gt/query_name.txt")
query_images_names = load_images_from_text_file(query_images_path)
query_cameras_bin_path = os.path.join(base_path, "gt/model/cameras.bin")
K = get_intrinsics_from_camera_bin(query_cameras_bin_path, 3)  # 3 because 1 -base, 2 -live, 3 -query images

# use OpenCV descriptors model, in output_opencv_sift_model/ !
db_gt_mnm_path = os.path.join(base_path_mnm, "gt/database.db")
db_gt_mnm = COLMAPDatabase.connect(db_gt_mnm_path)  # remember this database holds the OpenCV descriptors
# the "gt" here means ground truth (also used as query)
query_images_bin_path_mnm = os.path.join(base_path_mnm, "gt/output_opencv_sift_model/images.bin")
# "avg_descs_xyz_ml.npy" is generated by "get_points_3D_mean_desc_ml_mnm.py"
points3D_info_mnm = np.load(os.path.join(base_path_mnm, "avg_descs_xyz_ml.npy")).astype(np.float32) #notice I don't use ml_data here. It is more convinient to use "base_path_mnm"
train_descriptors_live_mnm = points3D_info_mnm[:, 0:128]
localised_query_images_names_mnm = get_localised_image_by_names(query_images_names, query_images_bin_path_mnm)
points3D_xyz_live_mnm = points3D_info_mnm[:,128:132]

# evaluation starts here
print("Feature matching using models..")
# db_gt, again because we need the descs from the query images
# PM (look at  MnM paper too) explains why the ratio test should not be used, so cite that
ratio_test_val = 1  # 0.9 as previous publication, 1.0 to test all features (no ratio test)

# NOTE: "model" needs to have a predict method and return predictions 0 and 1, not 0.5 or 0.12 or whatever
# NOTE: MnM needs to use the directories "*_mnm" as they contain the original data + the OpenCV data, in the databases and in "output_opencv_sift_model" (for base, live, gt)

print("Getting matches using Match or No Match: Keypoint Filtering based on Matching Probability + loading model (OpenCV)..")
model_path = os.path.join(comparison_data_path, f"Trained model {no_samples}.xml")
model = cv2.ml.RTrees_load(model_path)

# for MnM it doesn't matter if you use "base_path" or "base_path_mnm" it just reads the same images (live).
matches, images_matching_time, images_percentage_reduction = feature_matcher_wrapper_generic_comparison_model_mnm(base_path_mnm, comparison_data_path, model,
                                                                                                                  db_gt_mnm, localised_query_images_names_mnm,
                                                                                                                  train_descriptors_live_mnm, points3D_xyz_live_mnm, ratio_test_val)
np.save(os.path.join(comparison_data_path, "images_matching_time.npy"), images_matching_time)
np.save(os.path.join(comparison_data_path, "images_percentage_reduction.npy"), images_percentage_reduction)

print(" RANSAC..")
est_poses_results = benchmark(ransac, matches, localised_query_images_names_mnm, K)
np.save(os.path.join(comparison_data_path, "est_poses_results.npy"), est_poses_results)

print("Done!")