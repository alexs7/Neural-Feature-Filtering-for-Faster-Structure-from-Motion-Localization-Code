# This file is used to evaluate PM 2014 model.
import os
from joblib import load
from feature_matching_generator_ML_comparison_models import feature_matcher_wrapper_generic_comparison_model_pm
from database import COLMAPDatabase
import numpy as np
from ransac_prosac import ransac
from benchmark import benchmark
import sys
from query_image import load_images_from_text_file, get_localised_image_by_names, get_intrinsics_from_camera_bin

# This file is run after tranining the comparison models.
# The order is:
# 1 - run create_training_data_predicting_matchability.py, creates data for your python model and the original code C++
# 2 - train_for_predicting_matchability.py (choose the python model as it returns similar results to the original tool)
# 3 - choose a model based of learned_models_benchmarks.py csv file produced (after looking at the numbers).
# 4 - then this file

# Read the original file model_evaluator.py for notes.
# Similarly to model_evaluator.py, run in sequence NOT parallel

base_path = sys.argv[1]
print("Base path: " + base_path)
no_samples = sys.argv[2] #the model was trained on

ml_path = os.path.join(base_path, "ML_data")
# The directory should be already created from previous scripts, create_training_data_predicting_matchability.py, create_training_data_and_train_for_match_no_match.py
comparison_data_path = os.path.join(base_path, "predicting_matchability_comparison_data")

if((os.path.exists(comparison_data_path) == False)):
    raise Exception("One of the dirs is not created!")

print("Loading Data.. for PM")
query_images_path = os.path.join(base_path, "gt/query_name.txt")
query_images_names = load_images_from_text_file(query_images_path)
query_cameras_bin_path = os.path.join(base_path, "gt/model/cameras.bin")
K = get_intrinsics_from_camera_bin(query_cameras_bin_path, 3)  # 3 because 1 -base, 2 -live, 3 -query images

db_gt_path = os.path.join(base_path, "gt/database.db")
db_gt = COLMAPDatabase.connect(db_gt_path)  # you need this database to get the query images descs as they do NOT exist in the LIVE db, only in GT db!
# the "gt" here means ground truth (also used as query)
query_images_bin_path = os.path.join(base_path, "gt/model/images.bin")
# "avg_descs_xyz_ml.npy" is generated by "get_points_3D_mean_desc_ml_mnm.py"
points3D_info = np.load(os.path.join(ml_path, "avg_descs_xyz_ml.npy")).astype(np.float32)
train_descriptors_live = points3D_info[:, 0:128]
localised_query_images_names = get_localised_image_by_names(query_images_names, query_images_bin_path)
points3D_xyz_live = points3D_info[:,128:132]

# evaluation starts here
print("Feature matching using models..")
# db_gt, again because we need the descs from the query images
# PM paper explains why the ratio test should noe be used, so cite that
ratio_test_val = 1  # 0.9 as previous publication, 1.0 to test all features (no ratio test)

# NOTE: "model" needs to have a predict method and return predictions 0 and 1, not 0.5 or 0.12 or whatever
print("Getting matches using Predicting Matchability (2014) + loading model..")
model_path = os.path.join(comparison_data_path, f"rforest_{no_samples}.joblib")
model = load(model_path)
matches, images_matching_time, images_percentage_reduction = feature_matcher_wrapper_generic_comparison_model_pm(base_path, comparison_data_path, model,
                                                                                                                 db_gt, localised_query_images_names,
                                                                                                                 train_descriptors_live, points3D_xyz_live, ratio_test_val)
np.save(os.path.join(comparison_data_path, "images_matching_time.npy"), images_matching_time)
np.save(os.path.join(comparison_data_path, "images_percentage_reduction.npy"), images_percentage_reduction)

print(" RANSAC..")
est_poses_results = benchmark(ransac, matches, localised_query_images_names, K)
np.save(os.path.join(comparison_data_path, "est_poses_results.npy"), est_poses_results)

print("Done!")