# This file is used to evaluate PM 2014 model.
import os
from joblib import load
from feature_matching_generator_ML_comparison_models import feature_matcher_wrapper_generic_comparison_model_pm
from database import COLMAPDatabase
import numpy as np
from ransac_prosac import ransac
from benchmark import benchmark
import sys
from query_image import read_images_binary, load_images_from_text_file, get_localised_image_by_names, get_intrinsics_from_camera_bin

# This file is run after tranining the comparison models.
# The order is:
# 1 - TODO: complete this
# Read the original file model_evaluator.py for notes.
# Similarly to model_evaluator.py, run in sequence NOT parallel
# This file was added to evaluate:
# 1 - Predicting Matchability - PM (2014) paper - trained on their data (getting N neighbours for images that has N back/forw neighbours and the desc is matched if the kp is matched to a point)

base_path = sys.argv[1]
print("Base path: " + base_path)

ml_path = os.path.join(base_path, "ML_data")
prepared_data_path = os.path.join(ml_path, "prepared_data")

# The directory should be already created from previous scripts, train_for_comparison_models_on_my_3D_data.py, create_training_data_predicting_matchability.py, create_training_data_for_match_no_match.py
comparison_data_path_PM = os.path.join(base_path, "predicting_matchability_comparison_data")

if((os.path.exists(comparison_data_path_PM) == False)):
    raise Exception("One of the dirs is not created!")

print("Loading Data.. for PM")
query_images_path = os.path.join(base_path, "gt/query_name.txt")
query_images_names = load_images_from_text_file(query_images_path)
query_cameras_bin_path = os.path.join(base_path, "gt/model/cameras.bin")
K = get_intrinsics_from_camera_bin(query_cameras_bin_path, 3)  # 3 because 1 -base, 2 -live, 3 -query images

db_gt_path = os.path.join(base_path, "gt/database.db")
db_gt = COLMAPDatabase.connect(db_gt_path)  # you need this database to get the query images descs as they do NOT exist in the LIVE db, only in GT db!
# the "gt" here means ground truth (also used as query)
query_images_bin_path = os.path.join(base_path, "gt/model/images.bin")
# "avg_descs_xyz_ml.npy" is generated by "get_points_3D_mean_desc_single_model_ml.py"
points3D_info = np.load(os.path.join(ml_path, "avg_descs_xyz_ml.npy")).astype(np.float32)
train_descriptors_live = points3D_info[:, 0:128]
localised_query_images_names = get_localised_image_by_names(query_images_names, query_images_bin_path)
points3D_xyz_live = points3D_info[:,128:132]

# evaluation starts here
print("Feature matching using models..")
# db_gt, again because we need the descs from the query images
ratio_test_val = 1  # 0.9 as previous publication, 1.0 to test all features (no ratio test)

benchmarks_iters = 1
print("benchmarks_iters set to: " + str(benchmarks_iters))

# NOTE: "model" needs to have a predict method and return predictions 0 and 1, not 0.5 or 0.12 or whatever

print("Getting matches using Predicting Matchability (2014) + loading model..")
model_path = os.path.join(comparison_data_path_PM, "rf_model.joblib")
model = load(model_path)
matches, images_matching_time, images_percentage_reduction = feature_matcher_wrapper_generic_comparison_model_pm(base_path, comparison_data_path_PM, model, db_gt, localised_query_images_names, train_descriptors_live, points3D_xyz_live, ratio_test_val)
np.save(os.path.join(comparison_data_path_PM, "images_matching_time.npy"), images_matching_time)
np.save(os.path.join(comparison_data_path_PM, "images_percentage_reduction.npy"), images_percentage_reduction)

print(" RANSAC..")
est_poses_results = benchmark(benchmarks_iters, ransac, matches, localised_query_images_names, K)
np.save(os.path.join(comparison_data_path_PM, "est_poses_results.npy"), est_poses_results)

print("Done!")